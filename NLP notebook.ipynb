{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5afe99cd",
   "metadata": {},
   "source": [
    "# Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "7631ed93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "eca86405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
       "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>non-credible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
       "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>non-credible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
       "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 30, 2017</td>\n",
       "      <td>non-credible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump Is So Obsessed He Even Has Obama’s Name...</td>\n",
       "      <td>On Christmas day, Donald Trump announced that ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 29, 2017</td>\n",
       "      <td>non-credible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n",
       "      <td>Pope Francis used his annual Christmas Day mes...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 25, 2017</td>\n",
       "      <td>non-credible</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   Donald Trump Sends Out Embarrassing New Year’...   \n",
       "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
       "2   Sheriff David Clarke Becomes An Internet Joke...   \n",
       "3   Trump Is So Obsessed He Even Has Obama’s Name...   \n",
       "4   Pope Francis Just Called Out Donald Trump Dur...   \n",
       "\n",
       "                                                text subject  \\\n",
       "0  Donald Trump just couldn t wish all Americans ...    News   \n",
       "1  House Intelligence Committee Chairman Devin Nu...    News   \n",
       "2  On Friday, it was revealed that former Milwauk...    News   \n",
       "3  On Christmas day, Donald Trump announced that ...    News   \n",
       "4  Pope Francis used his annual Christmas Day mes...    News   \n",
       "\n",
       "                date         label  \n",
       "0  December 31, 2017  non-credible  \n",
       "1  December 31, 2017  non-credible  \n",
       "2  December 30, 2017  non-credible  \n",
       "3  December 29, 2017  non-credible  \n",
       "4  December 25, 2017  non-credible  "
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "fake_df = pd.read_csv('Fake.csv')\n",
    "true_df = pd.read_csv('True.csv')\n",
    "\n",
    "# Add a 'label' column to each DataFrame\n",
    "fake_df['label'] = 'non-credible'\n",
    "true_df['label'] = 'credible'\n",
    "\n",
    "# Concatenate the DataFrames\n",
    "df = pd.concat([fake_df, true_df], ignore_index=True)\n",
    "\n",
    "# Display the first few rows of the combined DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a88cbc1",
   "metadata": {},
   "source": [
    "- Imports the pandas library for data manipulation.\n",
    "- Loads two CSV files, 'Fake.csv' and 'True.csv', into separate DataFrames: `fake_df` and `true_df`.\n",
    "- Adds a new column called `label` to each DataFrame to indicate whether the news is 'credible' or 'non-credible'.\n",
    "- Concatenates the two DataFrames into a single DataFrame `df`, combining both credible and non-credible news articles.\n",
    "- Displays the first few rows of the combined DataFrame to provide an overview of the merged dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdc3176",
   "metadata": {},
   "source": [
    "# EDA and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2f469e",
   "metadata": {},
   "source": [
    "## Basic EDA / Dataset Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "0f9b6569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 44898 entries, 0 to 44897\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   title    44898 non-null  object\n",
      " 1   text     44898 non-null  object\n",
      " 2   subject  44898 non-null  object\n",
      " 3   date     44898 non-null  object\n",
      " 4   label    44898 non-null  object\n",
      "dtypes: object(5)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b5b617",
   "metadata": {},
   "source": [
    "The `df.info()` method provides a concise summary of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "3741f8cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44898, 5)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e681c3fd",
   "metadata": {},
   "source": [
    "The `df.shape` attribute returns a tuple representing the dimensions of the DataFrame.(rows and collumns)\n",
    "\n",
    "The output `(44898, 5)` indicates that the DataFrame `df` contains 44,898 rows and 5 columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f874df9d",
   "metadata": {},
   "source": [
    "## Dropping non essential features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "7130bb43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 44898 entries, 0 to 44897\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   title   44898 non-null  object\n",
      " 1   text    44898 non-null  object\n",
      " 2   label   44898 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 1.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(columns=['subject', 'date'])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e745f0",
   "metadata": {},
   "source": [
    "We dropped the `subject` and `date` columns because they are not essential for the initial analysis or modeling.\n",
    "Removing these columns helps to focus on the main textual content (`title`, `text`) and the target label (`label`). \n",
    "Additionally it also simplifies the dataset and reduces noise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7015901",
   "metadata": {},
   "source": [
    "## Combine Title and Text in to one collum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "7a4e2b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
       "      <td>non-credible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
       "      <td>non-credible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
       "      <td>non-credible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump Is So Obsessed He Even Has Obama’s Name...</td>\n",
       "      <td>non-credible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n",
       "      <td>non-credible</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content         label\n",
       "0   Donald Trump Sends Out Embarrassing New Year’...  non-credible\n",
       "1   Drunk Bragging Trump Staffer Started Russian ...  non-credible\n",
       "2   Sheriff David Clarke Becomes An Internet Joke...  non-credible\n",
       "3   Trump Is So Obsessed He Even Has Obama’s Name...  non-credible\n",
       "4   Pope Francis Just Called Out Donald Trump Dur...  non-credible"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['content'] = df['title'] + ' ' + df['text']\n",
    "df = df.drop(columns=['title', 'text'])\n",
    "df = df[['content', 'label']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a786e959",
   "metadata": {},
   "source": [
    "The code combines the \"title\" and \"text\" columns into a new \"content\" column, then removes the original \"title\" and \"text\" columns, leaving only \"content\" and \"label\" in the DataFrame. This simplifies the dataset by merging all relevant text into a single column for easier processing and analysis, and displays the first few rows of the updated DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4974b40e",
   "metadata": {},
   "source": [
    "## Converting text to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "972da970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>donald trump sends out embarrassing new year’...</td>\n",
       "      <td>non-credible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>drunk bragging trump staffer started russian ...</td>\n",
       "      <td>non-credible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sheriff david clarke becomes an internet joke...</td>\n",
       "      <td>non-credible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>trump is so obsessed he even has obama’s name...</td>\n",
       "      <td>non-credible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pope francis just called out donald trump dur...</td>\n",
       "      <td>non-credible</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content         label\n",
       "0   donald trump sends out embarrassing new year’...  non-credible\n",
       "1   drunk bragging trump staffer started russian ...  non-credible\n",
       "2   sheriff david clarke becomes an internet joke...  non-credible\n",
       "3   trump is so obsessed he even has obama’s name...  non-credible\n",
       "4   pope francis just called out donald trump dur...  non-credible"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['content'] = df['content'].str.lower()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380d67e6",
   "metadata": {},
   "source": [
    "code that maps the `'content'` collumn of the DateFrame to itself after converting it in to lower case using the `.str.lower()` method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408016c3",
   "metadata": {},
   "source": [
    "## Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "5e0078fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content    0\n",
      "label      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e69508",
   "metadata": {},
   "source": [
    "\n",
    "This code prints the number of missing (null) values in each column of the DataFrame `df\n",
    "\n",
    "The output shows us that the dataset has no missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45e06bb",
   "metadata": {},
   "source": [
    "## Finding and Handling Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "6a9d3f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "non-credible    23481\n",
      "credible        21417\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80090c29",
   "metadata": {},
   "source": [
    "The code takes the current DataFrame and uses the value_counts() method on the 'label' column to count the number of articles in each class (credible and non-credible)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "0741c76e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9942</th>\n",
       "      <td>hillary tweets message in defense of daca…oops...</td>\n",
       "      <td>non-credible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11446</th>\n",
       "      <td>former democrat warns young americans: “rioter...</td>\n",
       "      <td>non-credible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14925</th>\n",
       "      <td>[video] #blacklivesmatter terrorists storm dar...</td>\n",
       "      <td>non-credible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15892</th>\n",
       "      <td>house intel slaps subpoenas on mccain institut...</td>\n",
       "      <td>non-credible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15893</th>\n",
       "      <td>priceless! watch msnbc host’s shocked response...</td>\n",
       "      <td>non-credible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44709</th>\n",
       "      <td>france unveils labor reforms in first step to ...</td>\n",
       "      <td>credible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44744</th>\n",
       "      <td>guatemala top court sides with u.n. graft unit...</td>\n",
       "      <td>credible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44771</th>\n",
       "      <td>europeans, africans agree renewed push to tack...</td>\n",
       "      <td>credible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44834</th>\n",
       "      <td>thailand's ousted pm yingluck has fled abroad:...</td>\n",
       "      <td>credible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44889</th>\n",
       "      <td>u.s., north korea clash at u.n. forum over nuc...</td>\n",
       "      <td>credible</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5793 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 content         label\n",
       "9942   hillary tweets message in defense of daca…oops...  non-credible\n",
       "11446  former democrat warns young americans: “rioter...  non-credible\n",
       "14925  [video] #blacklivesmatter terrorists storm dar...  non-credible\n",
       "15892  house intel slaps subpoenas on mccain institut...  non-credible\n",
       "15893  priceless! watch msnbc host’s shocked response...  non-credible\n",
       "...                                                  ...           ...\n",
       "44709  france unveils labor reforms in first step to ...      credible\n",
       "44744  guatemala top court sides with u.n. graft unit...      credible\n",
       "44771  europeans, africans agree renewed push to tack...      credible\n",
       "44834  thailand's ousted pm yingluck has fled abroad:...      credible\n",
       "44889  u.s., north korea clash at u.n. forum over nuc...      credible\n",
       "\n",
       "[5793 rows x 2 columns]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicate_content = df[df.duplicated(subset='content')]\n",
    "duplicate_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec2c51f",
   "metadata": {},
   "source": [
    "The code creates a new DataFrame called `duplicate_content` that stores rows with duplicate values in the \"content\" column. This is achieved using the `duplicated()` function, which identifies all but the first occurrence of each duplicate which is later displayed. From the output we know that there are 5793 rows of duplicate values (first occurances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "14e7774a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "non-credible    5573\n",
      "credible         220\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(duplicate_content['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37277b25",
   "metadata": {},
   "source": [
    "The code takes the duplicate_content DataFrame using \".value_count()\" and displays the counts the number of articles in each class, The output shows that the most amount of duplicates are within the rows classified as \"non-credible\" articles at 5573 articles while only 220 \"credible\" artiles are duplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "06b4ca62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 39105 entries, 0 to 39104\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   content  39105 non-null  object\n",
      " 1   label    39105 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 611.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df = df.drop_duplicates(subset='content', keep='first').reset_index(drop=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6583541f",
   "metadata": {},
   "source": [
    "The `.drop_duplicates()` method is used to drop duplicate rows found in the `content` column, the `keep = first` parameter makes it so that the first occurance of the article in the dataset and drops the rest. `reset_index()` is used to reset the row index of the DataFrame after the drop opperation and the `drop=true` parameter makes sure that the old index is not added as a seperate collumn and is completely discarded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "fea43bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "credible        21197\n",
      "non-credible    17908\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6e02ab",
   "metadata": {},
   "source": [
    "DataFrame distribution after dropping duplicate content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "8e96f343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" the exact same texas lawmakers that voted against hurricane relief are now begging for help when hurricane sandy hit, affecting states all the way from north carolina to new england and particularly devastating new york and new jersey in 2012, texas lawmakers overwhelmingly voted against recovery assistance. in fact, john culberson, whose 7th congressional district includes parts of houston, was the only texas republican in congress in favor of the $50.7 billion relief effort.one of the loudest opponents of sandy aid was ted cruz, who was merely weeks away from becoming a texas senator. cruz s main concerns involved additional spending, which included funding for disaster preparedness and relief in other parts of the country as a means of gaining support for the hurricane sandy relief effort. hurricane sandy inflicted devastating damage on the east coast, and congress appropriately responded with hurricane relief,  cruz said in a statement at the time in an effort to justify his stance. unfortunately, cynical politicians in washington could not resist loading up this relief bill with billions in new spending utterly unrelated to sandy. now cruz, who campaigned for president of the united states, eventually losing the republican primary in indiana to donald trump in march of last year, has teamed up with fellow texas senator john cornyn to contact president trump, begging him to sign a major disaster declaration at the request of texas governor greg abbott, allowing the state to access key federal resources as soon as possible. given the potential catastrophic impact that the hurricane may have on texas communities,  cruz and cornyn wrote in their plea to trump,  we strongly support this request and urge you to provide any and all emergency protective measures available by a major disaster declaration. the irony of cruz s appeal to the president hasn t been lost on residents on the east coast. msnbc even quizzed cruz yesterday on the hypocritical nature of his request, but in typical fashion, cruz just avoided the question. there s time for political sniping later,  he said.  i think our focus needs to be on this crisis and this disaster. despite cruz abandoning them in their time of need five years ago, several new york and new jersey lawmakers have decided to take the high road and support cruz during his.despite my tx colleagues refusal to support aid in #southjersey time of need, i will support emergency disaster $$ for those impacted  frank lobiondo (@replobiondo) august 28, 2017disasters & emergencies are just that disasters & emergencies. must stand together as americans, not be hypocritical based on geography  frank lobiondo (@replobiondo) august 28, 2017ted cruz & texas cohorts voted vs ny/nj aid after sandy but i'll vote 4 harvey aid. ny wont abandon texas. 1 bad turn doesnt deserve another  rep. pete king (@reppeteking) august 27, 2017as lifelong nyer w/ ny values i will vote for emergency harvey $ for ted cruz's constituents. above all, true americans must stand together.  rep. pete king (@reppeteking) august 27, 2017others were also quick to mention that maybe cruz should also pursue the funding for disaster preparation that he was so opposed to when sandy hit.texans should hope cruz helps do what he criticized the sandy aid package for doing: get $ for future texas storm prep. he won't, of course.  chris hooks (@cd_hooks) august 28, 2017featured image via michael reynolds   pool/getty images\""
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['content'].iloc[476]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "c51417b6",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 34057\n",
      "content    imran khan's pti retains seat in by-election, ...\n",
      "label                                               credible\n",
      "Name: 34057, dtype: object\n",
      "----------------------------------------\n",
      "Index: 25513\n",
      "content    clinton says confident new emails will not cha...\n",
      "label                                               credible\n",
      "Name: 25513, dtype: object\n",
      "----------------------------------------\n",
      "Index: 476\n",
      "content     the exact same texas lawmakers that voted aga...\n",
      "label                                           non-credible\n",
      "Name: 476, dtype: object\n",
      "----------------------------------------\n",
      "Index: 22300\n",
      "content    trump adviser from wall street backs u.s. bank...\n",
      "label                                               credible\n",
      "Name: 22300, dtype: object\n",
      "----------------------------------------\n",
      "Index: 38393\n",
      "content    eu's barnier worried by uk's post-brexit plan ...\n",
      "label                                               credible\n",
      "Name: 38393, dtype: object\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Display 5 random rows that contain contractions in 'content'\n",
    "contraction_rows = df[df['content'].str.contains(contraction_pattern)]\n",
    "random_examples = contraction_rows.sample(5, random_state=42)\n",
    "for idx, row in random_examples.iterrows():\n",
    "    print(f\"Index: {idx}\")\n",
    "    print(row)\n",
    "    print('-' * 40)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c95de72",
   "metadata": {},
   "source": [
    "## Handling Contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "15f1556e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import contractions\n",
    "df['content'] = df['content'].apply(contractions.fix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "dcb71e0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" the exact same texas lawmakers that voted against hurricane relief are now begging for help when hurricane sandy hit, affecting states all the way from north carolina to new england and particularly devastating new york and new jersey in 2012, texas lawmakers overwhelmingly voted against recovery assistance. in fact, john culberson, whose 7th congressional district includes parts of houston, was the only texas republican in congress in favor of the $50.7 billion relief effort.one of the loudest opponents of sandy aid was ted cruz, who was merely weeks away from becoming a texas senator. cruz s main concerns involved additional spending, which included funding for disaster preparedness and relief in other parts of the country as a means of gaining support for the hurricane sandy relief effort. hurricane sandy inflicted devastating damage on the east coast, and congress appropriately responded with hurricane relief,  cruz said in a statement at the time in an effort to justify his stance. unfortunately, cynical politicians in washington could not resist loading up this relief bill with billions in new spending utterly unrelated to sandy. now cruz, who campaigned for president of the united states, eventually losing the republican primary in indiana to donald trump in march of last year, has teamed up with fellow texas senator john cornyn to contact president trump, begging him to sign a major disaster declaration at the request of texas governor greg abbott, allowing the state to access key federal resources as soon as possible. given the potential catastrophic impact that the hurricane may have on texas communities,  cruz and cornyn wrote in their plea to trump,  we strongly support this request and urge you to provide any and all emergency protective measures available by a major disaster declaration. the irony of cruz s appeal to the president hasn t been lost on residents on the east coast. msnbc even quizzed cruz yesterday on the hypocritical nature of his request, but in typical fashion, cruz just avoided the question. there s time for political sniping later,  he said.  i think our focus needs to be on this crisis and this disaster. despite cruz abandoning them in their time of need five years ago, several new york and new jersey lawmakers have decided to take the high road and support cruz during his.despite my tx colleagues refusal to support aid in #southjersey time of need, i will support emergency disaster $$ for those impacted  frank lobiondo (@replobiondo) august 28, 2017disasters & emergencies are just that disasters & emergencies. must stand together as americans, not be hypocritical based on geography  frank lobiondo (@replobiondo) august 28, 2017ted cruz & texas cohorts voted vs ny/nj aid after sandy but i will vote 4 harvey aid. ny will not abandon texas. 1 bad turn does not deserve another  rep. pete king (@reppeteking) august 27, 2017as lifelong nyer w/ ny values i will vote for emergency harvey $ for ted cruz's constituents. above all, true americans must stand together.  rep. pete king (@reppeteking) august 27, 2017others were also quick to mention that maybe cruz should also pursue the funding for disaster preparation that he was so opposed to when sandy hit.texans should hope cruz helps do what he criticized the sandy aid package for doing: get $ for future texas storm prep. he will not, of course.  chris hooks (@cd_hooks) august 28, 2017featured image via michael reynolds   pool/getty images\""
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['content'].iloc[476]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d507a5ec",
   "metadata": {},
   "source": [
    "## Finding and Handling usernames, hashtags, and emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "4cd0b7a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total email addresses: 44\n",
      "Total Twitter usernames: 24782\n"
     ]
    }
   ],
   "source": [
    "def count_users_hash(dataframe):\n",
    "\n",
    "    email_count = dataframe['content'].str.count(r'[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+').sum()\n",
    "    print(f\"Total email addresses: {email_count}\")\n",
    "    \n",
    "    username_count = dataframe['content'].str.count(r'@[A-Za-z0-9_]{1,15}\\b').sum()\n",
    "    print(f\"Total Twitter usernames: {username_count}\")\n",
    "\n",
    "\n",
    "count_users_hash(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "7576fba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total email addresses: 0\n",
      "Total Twitter usernames: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def clean_text(text):\n",
    "    \n",
    "    text = re.sub(r'[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+', '', text)\n",
    "\n",
    "    text = re.sub(r'@[A-Za-z0-9_]{1,15}\\b', '', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "df['content'] = df['content'].apply(clean_text)\n",
    "count_users_hash(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d27c08",
   "metadata": {},
   "source": [
    "## Finding and Handling HTML tags and URL's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "09073663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' donald trump sends out embarrassing new year’s eve message; this is disturbing donald trump just couldn t wish all americans a happy new year and leave it at that. instead, he had to give a shout out to his enemies, haters and  the very dishonest fake news media.  the former reality show star had just one job to do and he couldn t do it. as our country rapidly grows stronger and smarter, i want to wish all of my friends, supporters, enemies, haters, and even the very dishonest fake news media, a happy and healthy new year,  president angry pants tweeted.  2018 will be a great year for america! as our country rapidly grows stronger and smarter, i want to wish all of my friends, supporters, enemies, haters, and even the very dishonest fake news media, a happy and healthy new year. 2018 will be a great year for america!  donald j. trump () december 31, 2017trump s tweet went down about as welll as you d expect.what kind of president sends a new year s greeting like this despicable, petty, infantile gibberish? only trump! his lack of decency won t even allow him to rise above the gutter long enough to wish the american citizens a happy new year!  bishop talbert swan () december 31, 2017no one likes you  calvin () december 31, 2017your impeachment would make 2018 a great year for america, but i ll also accept regaining control of congress.  miranda yaver () december 31, 2017do you hear yourself talk? when you have to include that many people that hate you you have to wonder? why do the they all hate me?  alan sandoval () december 31, 2017who uses the word haters in a new years wish??  marlene () december 31, 2017you can t just say happy new year?  koren pollitt () december 31, 2017here s trump s new year s eve tweet from 2016.happy new year to all, including to my many enemies and those who have fought me and lost so badly they just don t know what to do. love!  donald j. trump () december 31, 2016this is nothing new for trump. he s been doing this for years.trump has directed messages to his  enemies  and  haters  for new year s, easter, thanksgiving, and the anniversary of 9/11. pic.twitter.com/4fpae2kypa  daniel dale () december 31, 2017trump s holiday tweets are clearly not presidential.how long did he work at hallmark before becoming president?  steven goodine () december 31, 2017he s always been like this . . . the only difference is that in the last few years, his filter has been breaking down.  roy schulze () december 31, 2017who, apart from a teenager uses the term haters?  wendy () december 31, 2017he s a fucking 5 year old  who knows () december 31, 2017so, to all the people who voted for this a hole thinking he would change once he got into power, you were wrong! 70-year-old men don t change and now he s a year older.photo by andrew burton/getty images.'"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['content'].iloc[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "7f1a6cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Links matching (abc.xyz.com(others)) pattern: 5845\n",
      "Rows with HTML tags: 68\n",
      "Rows with URLs: 2589\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(39105, 2)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_links(dataframe):\n",
    "\n",
    "    html_tag_count = df['content'].str.contains(r'<.*?>', regex=True).sum()\n",
    "    url_count = df['content'].str.contains(r'http\\S+|www\\.\\S+', regex=True).sum()\n",
    "    dot_com_count = df['content'].str.count(r'\\b\\w+\\.\\w+\\.(com|org|net|gov|edu|info|io|co|us|uk|in|au|ca|de|fr|ru|jp|cn|br|za)\\b').sum()\n",
    "    \n",
    "\n",
    "    print(f\"Links matching (abc.xyz.com(others)) pattern: {dot_com_count}\")\n",
    "    print(f\"Rows with HTML tags: {html_tag_count}\")\n",
    "    print(f\"Rows with URLs: {url_count}\")\n",
    "\n",
    "count_links(df)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "3376e91d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>donald trump sends out embarrassing new year’...</td>\n",
       "      <td>non-credible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>drunk bragging trump staffer started russian ...</td>\n",
       "      <td>non-credible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sheriff david clarke becomes an internet joke...</td>\n",
       "      <td>non-credible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>trump is so obsessed he even has obama’s name...</td>\n",
       "      <td>non-credible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pope francis just called out donald trump dur...</td>\n",
       "      <td>non-credible</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content         label\n",
       "0   donald trump sends out embarrassing new year’...  non-credible\n",
       "1   drunk bragging trump staffer started russian ...  non-credible\n",
       "2   sheriff david clarke becomes an internet joke...  non-credible\n",
       "3   trump is so obsessed he even has obama’s name...  non-credible\n",
       "4   pope francis just called out donald trump dur...  non-credible"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "\n",
    "    text = re.sub(r'\\b\\w+\\.\\w+\\.(com|org|net|gov|edu|info|io|co|us|uk|in|au|ca|de|fr|ru|jp|cn|br|za)\\b', '', text)\n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\.\\S+', '', text)\n",
    "    return text\n",
    "\n",
    "df['content'] = df['content'].apply(clean_text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "366a18c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Links matching (abc.xyz.com(others)) pattern: 0\n",
      "Rows with HTML tags: 0\n",
      "Rows with URLs: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(39105, 2)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_links(df)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "479f483b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' donald trump sends out embarrassing new year’s eve message; this is disturbing donald trump just couldn t wish all americans a happy new year and leave it at that. instead, he had to give a shout out to his enemies, haters and  the very dishonest fake news media.  the former reality show star had just one job to do and he couldn t do it. as our country rapidly grows stronger and smarter, i want to wish all of my friends, supporters, enemies, haters, and even the very dishonest fake news media, a happy and healthy new year,  president angry pants tweeted.  2018 will be a great year for america! as our country rapidly grows stronger and smarter, i want to wish all of my friends, supporters, enemies, haters, and even the very dishonest fake news media, a happy and healthy new year. 2018 will be a great year for america!  donald j. trump () december 31, 2017trump s tweet went down about as welll as you d expect.what kind of president sends a new year s greeting like this despicable, petty, infantile gibberish? only trump! his lack of decency won t even allow him to rise above the gutter long enough to wish the american citizens a happy new year!  bishop talbert swan () december 31, 2017no one likes you  calvin () december 31, 2017your impeachment would make 2018 a great year for america, but i ll also accept regaining control of congress.  miranda yaver () december 31, 2017do you hear yourself talk? when you have to include that many people that hate you you have to wonder? why do the they all hate me?  alan sandoval () december 31, 2017who uses the word haters in a new years wish??  marlene () december 31, 2017you can t just say happy new year?  koren pollitt () december 31, 2017here s trump s new year s eve tweet from 2016.happy new year to all, including to my many enemies and those who have fought me and lost so badly they just don t know what to do. love!  donald j. trump () december 31, 2016this is nothing new for trump. he s been doing this for years.trump has directed messages to his  enemies  and  haters  for new year s, easter, thanksgiving, and the anniversary of 9/11. /4fpae2kypa  daniel dale () december 31, 2017trump s holiday tweets are clearly not presidential.how long did he work at hallmark before becoming president?  steven goodine () december 31, 2017he s always been like this . . . the only difference is that in the last few years, his filter has been breaking down.  roy schulze () december 31, 2017who, apart from a teenager uses the term haters?  wendy () december 31, 2017he s a fucking 5 year old  who knows () december 31, 2017so, to all the people who voted for this a hole thinking he would change once he got into power, you were wrong! 70-year-old men don t change and now he s a year older.photo by andrew burton/getty images.'"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['content'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4045b3",
   "metadata": {},
   "source": [
    "## Handling Special characters and Digits (non-word and non-whitespaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "eb38bc72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>donald trump sends out embarrassing new years...</td>\n",
       "      <td>noncredible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>drunk bragging trump staffer started russian ...</td>\n",
       "      <td>noncredible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sheriff david clarke becomes an internet joke...</td>\n",
       "      <td>noncredible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>trump is so obsessed he even has obamas name ...</td>\n",
       "      <td>noncredible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pope francis just called out donald trump dur...</td>\n",
       "      <td>noncredible</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content        label\n",
       "0   donald trump sends out embarrassing new years...  noncredible\n",
       "1   drunk bragging trump staffer started russian ...  noncredible\n",
       "2   sheriff david clarke becomes an internet joke...  noncredible\n",
       "3   trump is so obsessed he even has obamas name ...  noncredible\n",
       "4   pope francis just called out donald trump dur...  noncredible"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.replace(to_replace=r'[^\\w\\s]', value='', regex=True)\n",
    "df = df.replace(to_replace=r'\\d', value='', regex=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea47fed",
   "metadata": {},
   "source": [
    "here the `df.replace()` function is used to replace all characters that are not(`^`) words ((a-z, A-Z), digits (0-9), and underscore (_)) (`\\w`) or whitespaces (`\\s`), and are replaces with an empty string (`value=''`). This is done to reduce noise and improve consistency as special characters often do not add any meaningful information to text classification and analytics casts and removing them helps standardize the text making future tokenizations and processing easier\n",
    "\n",
    "the code also replaces all digits (`\\d`) with and empty string\n",
    "\n",
    "Note: '[^\\w\\s]' = NOT (`^`) words or whitespaces while '\\d' = IS digits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ac76a4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "05e4c4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with extra white spaces: 38450\n",
      "Example with extra white spaces:\n",
      " donald trump sends out embarrassing new years eve message this is disturbing donald trump just couldn t wish all americans a happy new year and leave it at that instead he had to give a shout out to his enemies haters and  the very dishonest fake news media  the former reality show star had just one job to do and he couldn t do it as our country rapidly grows stronger and smarter i want to wish all of my friends supporters enemies haters and even the very dishonest fake news media a happy and healthy new year  president angry pants tweeted   will be a great year for america as our country rapidly grows stronger and smarter i want to wish all of my friends supporters enemies haters and even the very dishonest fake news media a happy and healthy new year  will be a great year for america  donald j trump  december  trump s tweet went down about as welll as you d expectwhat kind of president sends a new year s greeting like this despicable petty infantile gibberish only trump his lack of decency won t even allow him to rise above the gutter long enough to wish the american citizens a happy new year  bishop talbert swan  december  no one likes you  calvin  december  your impeachment would make  a great year for america but i ll also accept regaining control of congress  miranda yaver  december  do you hear yourself talk when you have to include that many people that hate you you have to wonder why do the they all hate me  alan sandoval  december  who uses the word haters in a new years wish  marlene  december  you can t just say happy new year  koren pollitt  december  here s trump s new year s eve tweet from happy new year to all including to my many enemies and those who have fought me and lost so badly they just don t know what to do love  donald j trump  december  this is nothing new for trump he s been doing this for yearstrump has directed messages to his  enemies  and  haters  for new year s easter thanksgiving and the anniversary of  fpaekypa  daniel dale  december  trump s holiday tweets are clearly not presidentialhow long did he work at hallmark before becoming president  steven goodine  december  he s always been like this    the only difference is that in the last few years his filter has been breaking down  roy schulze  december  who apart from a teenager uses the term haters  wendy  december  he s a fucking  year old  who knows  december  so to all the people who voted for this a hole thinking he would change once he got into power you were wrong yearold men don t change and now he s a year olderphoto by andrew burtongetty images\n"
     ]
    }
   ],
   "source": [
    "# Count rows with extra (consecutive) white spaces in 'content'\n",
    "extra_ws_mask = df['content'].str.contains(r'\\s{2,}', regex=True)\n",
    "extra_ws_count = extra_ws_mask.sum()\n",
    "print(f\"Rows with extra white spaces: {extra_ws_count}\")\n",
    "\n",
    "# Print an example row with extra white spaces, if any exist\n",
    "if extra_ws_count > 0:\n",
    "    example_row = df[extra_ws_mask].iloc[0]\n",
    "    print(\"Example with extra white spaces:\")\n",
    "    print(example_row['content'])\n",
    "else:\n",
    "    print(\"No extra white spaces found in the dataset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "156d6360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' donald trump sends out embarrassing new years eve message this is disturbing donald trump just couldn t wish all americans a happy new year and leave it at that instead he had to give a shout out to his enemies haters and  the very dishonest fake news media  the former reality show star had just one job to do and he couldn t do it as our country rapidly grows stronger and smarter i want to wish all of my friends supporters enemies haters and even the very dishonest fake news media a happy and healthy new year  president angry pants tweeted   will be a great year for america as our country rapidly grows stronger and smarter i want to wish all of my friends supporters enemies haters and even the very dishonest fake news media a happy and healthy new year  will be a great year for america  donald j trump  december  trump s tweet went down about as welll as you d expectwhat kind of president sends a new year s greeting like this despicable petty infantile gibberish only trump his lack of decency won t even allow him to rise above the gutter long enough to wish the american citizens a happy new year  bishop talbert swan  december  no one likes you  calvin  december  your impeachment would make  a great year for america but i ll also accept regaining control of congress  miranda yaver  december  do you hear yourself talk when you have to include that many people that hate you you have to wonder why do the they all hate me  alan sandoval  december  who uses the word haters in a new years wish  marlene  december  you can t just say happy new year  koren pollitt  december  here s trump s new year s eve tweet from happy new year to all including to my many enemies and those who have fought me and lost so badly they just don t know what to do love  donald j trump  december  this is nothing new for trump he s been doing this for yearstrump has directed messages to his  enemies  and  haters  for new year s easter thanksgiving and the anniversary of  fpaekypa  daniel dale  december  trump s holiday tweets are clearly not presidentialhow long did he work at hallmark before becoming president  steven goodine  december  he s always been like this    the only difference is that in the last few years his filter has been breaking down  roy schulze  december  who apart from a teenager uses the term haters  wendy  december  he s a fucking  year old  who knows  december  so to all the people who voted for this a hole thinking he would change once he got into power you were wrong yearold men don t change and now he s a year olderphoto by andrew burtongetty images'"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['content'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa87e655",
   "metadata": {},
   "source": [
    "## Handling extra whitespaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "e76d0cd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>donald trump sends out embarrassing new years ...</td>\n",
       "      <td>noncredible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>drunk bragging trump staffer started russian c...</td>\n",
       "      <td>noncredible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sheriff david clarke becomes an internet joke ...</td>\n",
       "      <td>noncredible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>trump is so obsessed he even has obamas name c...</td>\n",
       "      <td>noncredible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pope francis just called out donald trump duri...</td>\n",
       "      <td>noncredible</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content        label\n",
       "0  donald trump sends out embarrassing new years ...  noncredible\n",
       "1  drunk bragging trump staffer started russian c...  noncredible\n",
       "2  sheriff david clarke becomes an internet joke ...  noncredible\n",
       "3  trump is so obsessed he even has obamas name c...  noncredible\n",
       "4  pope francis just called out donald trump duri...  noncredible"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove extra (consecutive) white spaces from 'content'\n",
    "df['content'] = df['content'].str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "9914122e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'donald trump sends out embarrassing new years eve message this is disturbing donald trump just couldn t wish all americans a happy new year and leave it at that instead he had to give a shout out to his enemies haters and the very dishonest fake news media the former reality show star had just one job to do and he couldn t do it as our country rapidly grows stronger and smarter i want to wish all of my friends supporters enemies haters and even the very dishonest fake news media a happy and healthy new year president angry pants tweeted will be a great year for america as our country rapidly grows stronger and smarter i want to wish all of my friends supporters enemies haters and even the very dishonest fake news media a happy and healthy new year will be a great year for america donald j trump december trump s tweet went down about as welll as you d expectwhat kind of president sends a new year s greeting like this despicable petty infantile gibberish only trump his lack of decency won t even allow him to rise above the gutter long enough to wish the american citizens a happy new year bishop talbert swan december no one likes you calvin december your impeachment would make a great year for america but i ll also accept regaining control of congress miranda yaver december do you hear yourself talk when you have to include that many people that hate you you have to wonder why do the they all hate me alan sandoval december who uses the word haters in a new years wish marlene december you can t just say happy new year koren pollitt december here s trump s new year s eve tweet from happy new year to all including to my many enemies and those who have fought me and lost so badly they just don t know what to do love donald j trump december this is nothing new for trump he s been doing this for yearstrump has directed messages to his enemies and haters for new year s easter thanksgiving and the anniversary of fpaekypa daniel dale december trump s holiday tweets are clearly not presidentialhow long did he work at hallmark before becoming president steven goodine december he s always been like this the only difference is that in the last few years his filter has been breaking down roy schulze december who apart from a teenager uses the term haters wendy december he s a fucking year old who knows december so to all the people who voted for this a hole thinking he would change once he got into power you were wrong yearold men don t change and now he s a year olderphoto by andrew burtongetty images'"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['content'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95173030",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37537e68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a48b12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9391ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b861fd5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144570ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfa01af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6f2f79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f9b880",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2968a1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1574cdc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fe3cd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f038439c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c539ab9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef462e78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02e5898",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00fbaae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7d53de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0731a8c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2eb929",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de0eb16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eec477c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c71422",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efcac63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85180324",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20c6c80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ae5eef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2eac55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146ae22c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bdb6e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bfa324",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c06b40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afca814",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4b14c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4704904",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c999fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad6ed1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f1741b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcc74e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eff5bd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef52558",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2953ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61da4ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c48d50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea0e34b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0687b7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a81ecc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ee6259",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7aacf8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30298901",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55ee618",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02df23b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18dfbfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bfc8ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a2e2b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bdef61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d52011",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b6d759",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74a51d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6306e209",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca283e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b103cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a1a7a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2ce770",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7b195e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d12a4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1c2adb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ce2545",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c1bd1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccf029e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02d5faf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602a7e59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78a018e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f22b3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a0ac26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d49e6e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c01c13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8985a86b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a454fdc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8e3dc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743bd16d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acb7c39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e94e4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f445d413",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b285f8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702af317",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97480f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32511872",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1462a7e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e775558e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1646aad3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7612712a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625c9acd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1df11a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e60cbeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9a55df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae7e3ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8baadb5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00893c9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8450d5f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934d4755",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e234a1a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893bdd43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60acc365",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48dbfed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a5123e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548e679a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95e8c66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed0722f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d649ba2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51926fd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec96b34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb61df7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b98b09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b64498e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb240317",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d89209",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac34400",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552ef96c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6923da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c303d3be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8475cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404c6528",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fd25d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b98ee54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de40b09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b99995",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a45172",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0467a43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f87fca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a61c5e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea24404a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078d36b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d9596e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7fc12a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74c9424",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29da9251",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6088e7cf",
   "metadata": {},
   "source": [
    "## Handling missing whitespaces (Experimental, remove if bad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4359774",
   "metadata": {},
   "source": [
    "based on `https://stackoverflow.com/questions/8870261/how-to-split-text-without-spaces-into-list-of-words`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "7b0d35f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wordninja\n",
    "\n",
    "df['content'] = df['content'].apply(lambda x: ' '.join(wordninja.split(x)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "eb3268a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'donald trump sends out embarrassing new years eve message this is disturbing donald trump just couldn t wish all americans a happy new year and leave it at that instead he had to give a shout out to his enemies haters and the very dishonest fake news media the former reality show star had just one job to do and he couldn t do it as our country rapidly grows stronger and smarter i want to wish all of my friends supporters enemies haters and even the very dishonest fake news media a happy and healthy new year president angry pants tweeted will be a great year for america as our country rapidly grows stronger and smarter i want to wish all of my friends supporters enemies haters and even the very dishonest fake news media a happy and healthy new year will be a great year for america donald j trump december trump s tweet went down about as well l as you d expect what kind of president sends a new year s greeting like this despicable petty infantile gibberish only trump his lack of decency won t even allow him to rise above the gutter long enough to wish the american citizens a happy new year bishop t albert swan december no one likes you calvin december your impeachment would make a great year for america but i ll also accept regaining control of congress miranda y aver december do you hear yourself talk when you have to include that many people that hate you you have to wonder why do the they all hate me alan sandoval december who uses the word haters in a new years wish marlene december you can t just say happy new year kore n poll it t december here s trump s new year s eve tweet from happy new year to all including to my many enemies and those who have fought me and lost so badly they just don t know what to do love donald j trump december this is nothing new for trump he s been doing this for years trump has directed messages to his enemies and haters for new year s easter thanksgiving and the anniversary of f pae ky pa daniel dale december trump s holiday tweets are clearly not presidential how long did he work at hallmark before becoming president steven good in e december he s always been like this the only difference is that in the last few years his filter has been breaking down roy schulze december who apart from a teenager uses the term haters wendy december he s a fucking year old who knows december so to all the people who voted for this a hole thinking he would change once he got into power you were wrong year old men don t change and now he s a year older photo by andrew burton getty images'"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['content'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "95deeb92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>donald trump sends out embarrassing new years ...</td>\n",
       "      <td>noncredible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>drunk bragging trump staffer started russian c...</td>\n",
       "      <td>noncredible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sheriff david clarke becomes an internet joke ...</td>\n",
       "      <td>noncredible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>trump is so obsessed he even has obama s name ...</td>\n",
       "      <td>noncredible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pope francis just called out donald trump duri...</td>\n",
       "      <td>noncredible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39100</th>\n",
       "      <td>fully committed nato backs new you s approach ...</td>\n",
       "      <td>credible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39101</th>\n",
       "      <td>lex isn ex is withdrew two products from chine...</td>\n",
       "      <td>credible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39102</th>\n",
       "      <td>minsk cultural hub becomes haven from authorit...</td>\n",
       "      <td>credible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39103</th>\n",
       "      <td>vatican upbeat on possibility of pope francis ...</td>\n",
       "      <td>credible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39104</th>\n",
       "      <td>indonesia to buy billion worth of russian jets...</td>\n",
       "      <td>credible</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39105 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 content        label\n",
       "0      donald trump sends out embarrassing new years ...  noncredible\n",
       "1      drunk bragging trump staffer started russian c...  noncredible\n",
       "2      sheriff david clarke becomes an internet joke ...  noncredible\n",
       "3      trump is so obsessed he even has obama s name ...  noncredible\n",
       "4      pope francis just called out donald trump duri...  noncredible\n",
       "...                                                  ...          ...\n",
       "39100  fully committed nato backs new you s approach ...     credible\n",
       "39101  lex isn ex is withdrew two products from chine...     credible\n",
       "39102  minsk cultural hub becomes haven from authorit...     credible\n",
       "39103  vatican upbeat on possibility of pope francis ...     credible\n",
       "39104  indonesia to buy billion worth of russian jets...     credible\n",
       "\n",
       "[39105 rows x 2 columns]"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aab4f60",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "efbd8672",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\eksudee\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\eksudee\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\eksudee\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt_tab') # for tokenization\n",
    "nltk.download('averaged_perceptron_tagger_eng') # for POS Tagging\n",
    "nltk.download('wordnet') # for tokenization\n",
    "from textblob import Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "6db21d15",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[259]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Tokenize the 'content' column and store the result in a new column 'tokens'\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mTextBlob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwords\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m df.head()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\core\\series.py:4935\u001b[39m, in \u001b[36mSeries.apply\u001b[39m\u001b[34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[39m\n\u001b[32m   4800\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply\u001b[39m(\n\u001b[32m   4801\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   4802\u001b[39m     func: AggFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m   4807\u001b[39m     **kwargs,\n\u001b[32m   4808\u001b[39m ) -> DataFrame | Series:\n\u001b[32m   4809\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4810\u001b[39m \u001b[33;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[32m   4811\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   4926\u001b[39m \u001b[33;03m    dtype: float64\u001b[39;00m\n\u001b[32m   4927\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   4928\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4929\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   4930\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4931\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4932\u001b[39m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4933\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4934\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m-> \u001b[39m\u001b[32m4935\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\core\\apply.py:1422\u001b[39m, in \u001b[36mSeriesApply.apply\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1419\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_compat()\n\u001b[32m   1421\u001b[39m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1422\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\core\\apply.py:1502\u001b[39m, in \u001b[36mSeriesApply.apply_standard\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1496\u001b[39m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[32m   1497\u001b[39m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[32m   1498\u001b[39m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[32m   1499\u001b[39m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[32m   1500\u001b[39m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[32m   1501\u001b[39m action = \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj.dtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1502\u001b[39m mapped = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1503\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[32m   1504\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1506\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[32m0\u001b[39m], ABCSeries):\n\u001b[32m   1507\u001b[39m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[32m   1508\u001b[39m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj._constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index=obj.index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\core\\base.py:925\u001b[39m, in \u001b[36mIndexOpsMixin._map_values\u001b[39m\u001b[34m(self, mapper, na_action, convert)\u001b[39m\n\u001b[32m    922\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[32m    923\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m arr.map(mapper, na_action=na_action)\n\u001b[32m--> \u001b[39m\u001b[32m925\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[39m, in \u001b[36mmap_array\u001b[39m\u001b[34m(arr, mapper, na_action, convert)\u001b[39m\n\u001b[32m   1741\u001b[39m values = arr.astype(\u001b[38;5;28mobject\u001b[39m, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1742\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1743\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1745\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m lib.map_infer_mask(\n\u001b[32m   1746\u001b[39m         values, mapper, mask=isna(values).view(np.uint8), convert=convert\n\u001b[32m   1747\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/lib.pyx:2999\u001b[39m, in \u001b[36mpandas._libs.lib.map_infer\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[259]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36m<lambda>\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Tokenize the 'content' column and store the result in a new column 'tokens'\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m'\u001b[39m] = df[\u001b[33m'\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m'\u001b[39m].apply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mTextBlob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwords\u001b[49m)\n\u001b[32m      3\u001b[39m df.head()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\textblob\\decorators.py:23\u001b[39m, in \u001b[36mcached_property.__get__\u001b[39m\u001b[34m(self, obj, cls)\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     22\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m value = obj.\u001b[34m__dict__\u001b[39m[\u001b[38;5;28mself\u001b[39m.func.\u001b[34m__name__\u001b[39m] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\textblob\\blob.py:625\u001b[39m, in \u001b[36mTextBlob.words\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    617\u001b[39m \u001b[38;5;129m@cached_property\u001b[39m\n\u001b[32m    618\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwords\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    619\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return a list of word tokens. This excludes punctuation characters.\u001b[39;00m\n\u001b[32m    620\u001b[39m \u001b[33;03m    If you want to include punctuation characters, access the ``tokens``\u001b[39;00m\n\u001b[32m    621\u001b[39m \u001b[33;03m    property.\u001b[39;00m\n\u001b[32m    622\u001b[39m \n\u001b[32m    623\u001b[39m \u001b[33;03m    :returns: A :class:`WordList <WordList>` of word tokens.\u001b[39;00m\n\u001b[32m    624\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m625\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mWordList\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_punc\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\textblob\\blob.py:205\u001b[39m, in \u001b[36mWordList.__init__\u001b[39m\u001b[34m(self, collection)\u001b[39m\n\u001b[32m    201\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, collection):\n\u001b[32m    202\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Initialize a WordList. Takes a collection of strings as\u001b[39;00m\n\u001b[32m    203\u001b[39m \u001b[33;03m    its only argument.\u001b[39;00m\n\u001b[32m    204\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m([\u001b[43mWord\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m collection])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\textblob\\blob.py:80\u001b[39m, in \u001b[36mWord.__init__\u001b[39m\u001b[34m(self, string, pos_tag)\u001b[39m\n\u001b[32m     74\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return a new instance of the class. It is necessary to override\u001b[39;00m\n\u001b[32m     75\u001b[39m \u001b[33;03m    this method in order to handle the extra pos_tag argument in the\u001b[39;00m\n\u001b[32m     76\u001b[39m \u001b[33;03m    constructor.\u001b[39;00m\n\u001b[32m     77\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m     78\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, string)\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, string, pos_tag=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     81\u001b[39m     \u001b[38;5;28mself\u001b[39m.string = string\n\u001b[32m     82\u001b[39m     \u001b[38;5;28mself\u001b[39m.pos_tag = pos_tag\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Tokenize the 'content' column and store the result in a new column 'tokens'\n",
    "df['content'] = df['content'].apply(lambda x: TextBlob(x).words)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a8d7ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['donald', 'trump', 'sends', 'out', 'embarrassing', 'new', 'years', 'eve', 'message', 'this', 'is', 'disturbing', 'donald', 'trump', 'just', 'couldn', 't', 'wish', 'all', 'americans', 'a', 'happy', 'new', 'year', 'and', 'leave', 'it', 'at', 'that', 'instead', 'he', 'had', 'to', 'give', 'a', 'shout', 'out', 'to', 'his', 'enemies', 'haters', 'and', 'the', 'very', 'dishonest', 'fake', 'news', 'media', 'the', 'former', 'reality', 'show', 'star', 'had', 'just', 'one', 'job', 'to', 'do', 'and', 'he', 'couldn', 't', 'do', 'it', 'as', 'our', 'country', 'rapidly', 'grows', 'stronger', 'and', 'smarter', 'i', 'want', 'to', 'wish', 'all', 'of', 'my', 'friends', 'supporters', 'enemies', 'haters', 'and', 'even', 'the', 'very', 'dishonest', 'fake', 'news', 'media', 'a', 'happy', 'and', 'healthy', 'new', 'year', 'president', 'angry', 'pants', 'tweeted', 'will', 'be', 'a', 'great', 'year', 'for', 'america', 'as', 'our', 'country', 'rapidly', 'grows', 'stronger', 'and', 'smarter', 'i', 'want', 'to', 'wish', 'all', 'of', 'my', 'friends', 'supporters', 'enemies', 'haters', 'and', 'even', 'the', 'very', 'dishonest', 'fake', 'news', 'media', 'a', 'happy', 'and', 'healthy', 'new', 'year', 'will', 'be', 'a', 'great', 'year', 'for', 'america', 'donald', 'j', 'trump', 'december', 'trump', 's', 'tweet', 'went', 'down', 'about', 'as', 'well', 'l', 'as', 'you', 'd', 'expect', 'what', 'kind', 'of', 'president', 'sends', 'a', 'new', 'year', 's', 'greeting', 'like', 'this', 'despicable', 'petty', 'infantile', 'gibberish', 'only', 'trump', 'his', 'lack', 'of', 'decency', 'won', 't', 'even', 'allow', 'him', 'to', 'rise', 'above', 'the', 'gutter', 'long', 'enough', 'to', 'wish', 'the', 'american', 'citizens', 'a', 'happy', 'new', 'year', 'bishop', 't', 'albert', 'swan', 'december', 'no', 'one', 'likes', 'you', 'calvin', 'december', 'your', 'impeachment', 'would', 'make', 'a', 'great', 'year', 'for', 'america', 'but', 'i', 'll', 'also', 'accept', 'regaining', 'control', 'of', 'congress', 'miranda', 'y', 'aver', 'december', 'do', 'you', 'hear', 'yourself', 'talk', 'when', 'you', 'have', 'to', 'include', 'that', 'many', 'people', 'that', 'hate', 'you', 'you', 'have', 'to', 'wonder', 'why', 'do', 'the', 'they', 'all', 'hate', 'me', 'alan', 'sandoval', 'december', 'who', 'uses', 'the', 'word', 'haters', 'in', 'a', 'new', 'years', 'wish', 'marlene', 'december', 'you', 'can', 't', 'just', 'say', 'happy', 'new', 'year', 'kore', 'n', 'poll', 'it', 't', 'december', 'here', 's', 'trump', 's', 'new', 'year', 's', 'eve', 'tweet', 'from', 'happy', 'new', 'year', 'to', 'all', 'including', 'to', 'my', 'many', 'enemies', 'and', 'those', 'who', 'have', 'fought', 'me', 'and', 'lost', 'so', 'badly', 'they', 'just', 'don', 't', 'know', 'what', 'to', 'do', 'love', 'donald', 'j', 'trump', 'december', 'this', 'is', 'nothing', 'new', 'for', 'trump', 'he', 's', 'been', 'doing', 'this', 'for', 'years', 'trump', 'has', 'directed', 'messages', 'to', 'his', 'enemies', 'and', 'haters', 'for', 'new', 'year', 's', 'easter', 'thanksgiving', 'and', 'the', 'anniversary', 'of', 'f', 'pae', 'ky', 'pa', 'daniel', 'dale', 'december', 'trump', 's', 'holiday', 'tweets', 'are', 'clearly', 'not', 'presidential', 'how', 'long', 'did', 'he', 'work', 'at', 'hallmark', 'before', 'becoming', 'president', 'steven', 'good', 'in', 'e', 'december', 'he', 's', 'always', 'been', 'like', 'this', 'the', 'only', 'difference', 'is', 'that', 'in', 'the', 'last', 'few', 'years', 'his', 'filter', 'has', 'been', 'breaking', 'down', 'roy', 'schulze', 'december', 'who', 'apart', 'from', 'a', 'teenager', 'uses', 'the', 'term', 'haters', 'wendy', 'december', 'he', 's', 'a', 'fucking', 'year', 'old', 'who', 'knows', 'december', 'so', 'to', 'all', 'the', 'people', 'who', 'voted', 'for', 'this', 'a', 'hole', 'thinking', 'he', 'would', 'change', 'once', 'he', 'got', 'into', 'power', 'you', 'were', 'wrong', 'year', 'old', 'men', 'don', 't', 'change', 'and', 'now', 'he', 's', 'a', 'year', 'older', 'photo', 'by', 'andrew', 'burton', 'getty', 'images'])"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
